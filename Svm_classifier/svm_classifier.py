# -*- coding: utf-8 -*-
"""ML_assignment1___ipynb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VJWobNnXywjcjdEN8Gmqzm92z7RTvtia

#Classification using Support Vector Machine
Please do not import any other python library except numpy and matplotlib
"""

import numpy as np
import matplotlib.pyplot as plt

"""#Generating Random linearly separable data

"""

data = [[np.random.rand(), np.random.rand()] for i in range(10)]
for i, point in enumerate(data):
  x, y = point
  if 0.5*x - y + 0.25 > 0:
    data[i].append(-1)
  else:
    data[i].append(1)
print(data)

"""#Visualizing the above data"""

for x, y, l in data:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
  plt.xlim(0,1)
  plt.ylim(0,1)

"""#SVM Classifier
Train a SVM classifier using gradient descent and return a Weight Matrix which is a numpy array of length (N + 1) where N is dimension of training samples. 
You can refer to Fig. 1 in [this](https://www.cs.huji.ac.il/~shais/papers/ShalevSiSrCo10.pdf) paper for implementation. You can add arguments to svm_function according to your implementation.
"""

###################################
    ### Write your code here###########
    ###################################
def svm_function(x, y, epoch, l_rate):
    w = np.zeros(2)
    b = 0
    for t in range(epoch):
      eta = 1/(l_rate * (t + 1))
      for index, p in enumerate(x):
       condition = y[index] * (np.dot(w,p) + b)
       if (condition >= 1):
         w = w - (l_rate * eta * w)
       else:
         w = w - (eta * l_rate * w) + (eta * y[index] * p)
         b = b + eta * y[index]
    return w[0],w[1],b

"""#Run SVM Classifier"""

data = np.asarray(data)
X = data[:,:2]
Y = data[:,2]
W = svm_function(X, Y, 150000, 0.0002)
print(W)

"""#Visualize the classifier
Write a code to draw a lines corrosponding to 'w' vector you got as output from svm_function and for a line from which actual data was generated
(0.5*x - y + 0.25). 
"""

###################################
    ### Write your code here###########
    ###################################

x = np.linspace(0,1,100)
plt.plot(x, 0.5*x + 0.25, '-c')
plt.plot(x, -(W[0]*x + W[2])/W[1], '-k')
plt.plot(x, -(W[0]*x + W[2] + 1)/W[1], '--g')
plt.plot(x, -(W[0]*x + W[2] - 1)/W[1], '--g')

for x, y, l in data:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)

"""Increase the number of data-points and observe number of epochs to converge. Draw plots showing data-points, actual data seprating line and line corrosponding to 'w' you got from svm_function for 10, 20, 30, 40, 50 and 100 data-points. Please use only one notebook cell for this visualization. Please use subplot function in matplotlib for this."""

###################################
    ### Write your code here###########
    ###################################
def gendata(no_of_points):
      data = [[np.random.rand(), np.random.rand()] for i in range(no_of_points)]
      for i, point in enumerate(data):
        x, y = point
        if 0.5*x - y + 0.25 > 0:
          data[i].append(-1)
        else:
          data[i].append(1)
      return data
##10 data points##
data1 = gendata(10)    
data1 = np.asarray(data1)
X1 = data1[:,:2]
Y1 = data1[:,2]
W1 = svm_function(X1, Y1, 100000, 0.0002)
plt.subplot(2,3,1)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W1[0]*xaxis + W1[2])/W1[1], '-k')
plt.plot(xaxis, -(W1[0]*xaxis + W1[2] + 1)/W1[1], '--g')
plt.plot(xaxis, -(W1[0]*xaxis + W1[2] - 1)/W1[1], '--g')
for x, y, l in data1:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##20 data points##
data2 = gendata(20)    
data2 = np.asarray(data2)
X2 = data2[:,:2]
Y2 = data2[:,2]
W2 = svm_function(X2, Y2, 100000, 0.0002)
plt.subplot(2,3,2)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W2[0]*xaxis + W2[2])/W2[1], '-k')
plt.plot(xaxis, -(W2[0]*xaxis + W2[2] + 1)/W2[1], '--g')
plt.plot(xaxis, -(W2[0]*xaxis + W2[2] - 1)/W2[1], '--g')
for x, y, l in data2:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##30 data points##
data3 = gendata(30)    
data3 = np.asarray(data3)
X3 = data3[:,:2]
Y3 = data3[:,2]
W3 = svm_function(X3, Y3, 200000, 0.0002)
plt.subplot(2,3,3)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W3[0]*xaxis + W3[2])/W3[1], '-k')
plt.plot(xaxis, -(W3[0]*xaxis + W3[2] + 1)/W3[1], '--g')
plt.plot(xaxis, -(W3[0]*xaxis + W3[2] - 1)/W3[1], '--g')
for x, y, l in data3:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##40 data points##
data4 = gendata(40)    
data4 = np.asarray(data4)
X4 = data4[:,:2]
Y4 = data4[:,2]
W4 = svm_function(X4, Y4, 200000, 0.0002)
plt.subplot(2,3,4)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W4[0]*xaxis + W4[2])/W4[1], '-k')
plt.plot(xaxis, -(W4[0]*xaxis + W4[2] + 1)/W4[1], '--g')
plt.plot(xaxis, -(W4[0]*xaxis + W4[2] - 1)/W4[1], '--g')
for x, y, l in data4:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##50 data points##
data5 = gendata(50)    
data5 = np.asarray(data5)
X5 = data5[:,:2]
Y5 = data5[:,2]
W5 = svm_function(X5, Y5, 200000, 0.00015)
plt.subplot(2,3,5)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W5[0]*xaxis + W5[2])/W5[1], '-k')
plt.plot(xaxis, -(W5[0]*xaxis + W5[2] + 1)/W5[1], '--g')
plt.plot(xaxis, -(W5[0]*xaxis + W5[2] - 1)/W5[1], '--g')
for x, y, l in data5:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##100 data points##
data6 = gendata(100)    
data6 = np.asarray(data6)
X6 = data6[:,:2]
Y6 = data6[:,2]
W6 = svm_function(X6, Y6, 250000, 0.00002)
plt.subplot(2,3,6)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W6[0]*xaxis + W6[2])/W6[1], '-k')
plt.plot(xaxis, -(W6[0]*xaxis + W6[2] + 1)/W6[1], '--g')
plt.plot(xaxis, -(W6[0]*xaxis + W6[2] - 1)/W6[1], '--g')
for x, y, l in data6:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)

"""#Perturbing the previously created  data
Add noise to the data and visualize the resulting classifier.



"""

for i in range(len(data)):
  data[i][0] += (np.random.rand() - 0.5) / 2.
  data[i][1] += (np.random.rand() - 0.5) / 2.

"""#Visualizing the perturbed Data"""

for x, y, l in data:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
  plt.xlim(-0.5,1.5)
  plt.ylim(-0.5,1.5)

"""#Visualize the classifier trained on noisy data
Plot actual seperating line and seperating line you got from svm_classifier. Do this for 10, 20, 30, 40, 50 and 100 data points. You can vary the scale of noise as well. Please use only one notebook cell for this visualization. Please use subplot function in matplotlib for this.
"""

###################################
    ### Write your code here###########
    ###################################
def gendata(no_of_points):
      data = [[np.random.rand(), np.random.rand()] for i in range(no_of_points)]
      for i, point in enumerate(data):
        x, y = point
        if 0.5*x - y + 0.25 > 0:
          data[i].append(-1)
        else:
          data[i].append(1)
      for i in range(len(data)):
        data[i][0] += (np.random.rand() - 0.5) / 2.
        data[i][1] += (np.random.rand() - 0.5) / 2.
        return data
##10 data points##
data1 = gendata(10)    
data1 = np.asarray(data1)
X1 = data1[:,:2]
Y1 = data1[:,2]
W1 = svm_function(X1, Y1, 100000, 0.0002)
plt.subplot(2,3,1)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W1[0]*xaxis + W1[2])/W1[1], '-k')
plt.plot(xaxis, -(W1[0]*xaxis + W1[2] + 1)/W1[1], '--g')
plt.plot(xaxis, -(W1[0]*xaxis + W1[2] - 1)/W1[1], '--g')
for x, y, l in data1:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##20 data points##
data2 = gendata(20)    
data2 = np.asarray(data2)
X2 = data2[:,:2]
Y2 = data2[:,2]
W2 = svm_function(X2, Y2, 100000, 0.0002)
plt.subplot(2,3,2)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W2[0]*xaxis + W2[2])/W2[1], '-k')
plt.plot(xaxis, -(W2[0]*xaxis + W2[2] + 1)/W2[1], '--g')
plt.plot(xaxis, -(W2[0]*xaxis + W2[2] - 1)/W2[1], '--g')
for x, y, l in data2:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##30 data points##
data3 = gendata(30)    
data3 = np.asarray(data3)
X3 = data3[:,:2]
Y3 = data3[:,2]
W3 = svm_function(X3, Y3, 200000, 0.0002)
plt.subplot(2,3,3)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W3[0]*xaxis + W3[2])/W3[1], '-k')
plt.plot(xaxis, -(W3[0]*xaxis + W3[2] + 1)/W3[1], '--g')
plt.plot(xaxis, -(W3[0]*xaxis + W3[2] - 1)/W3[1], '--g')
for x, y, l in data3:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##40 data points##
data4 = gendata(40)    
data4 = np.asarray(data4)
X4 = data4[:,:2]
Y4 = data4[:,2]
W4 = svm_function(X4, Y4, 200000, 0.0002)
plt.subplot(2,3,4)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W4[0]*xaxis + W4[2])/W4[1], '-k')
plt.plot(xaxis, -(W4[0]*xaxis + W4[2] + 1)/W4[1], '--g')
plt.plot(xaxis, -(W4[0]*xaxis + W4[2] - 1)/W4[1], '--g')
for x, y, l in data4:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##50 data points##
data5 = gendata(50)    
data5 = np.asarray(data5)
X5 = data5[:,:2]
Y5 = data5[:,2]
W5 = svm_function(X5, Y5, 200000, 0.00015)
plt.subplot(2,3,5)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W5[0]*xaxis + W5[2])/W5[1], '-k')
plt.plot(xaxis, -(W5[0]*xaxis + W5[2] + 1)/W5[1], '--g')
plt.plot(xaxis, -(W5[0]*xaxis + W5[2] - 1)/W5[1], '--g')
for x, y, l in data5:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
##100 data points##
data6 = gendata(100)    
data6 = np.asarray(data6)
X6 = data6[:,:2]
Y6 = data6[:,2]
W6 = svm_function(X6, Y6, 250000, 0.00002)
plt.subplot(2,3,6)
xaxis = np.linspace(0,1,100)
plt.plot(xaxis, 0.5*xaxis + 0.25, '-c')
plt.plot(xaxis, -(W6[0]*xaxis + W6[2])/W6[1], '-k')
plt.plot(xaxis, -(W6[0]*xaxis + W6[2] + 1)/W6[1], '--g')
plt.plot(xaxis, -(W6[0]*xaxis + W6[2] - 1)/W6[1], '--g')
for x, y, l in data6:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)

"""#Read the Random Non-linear data stored in CSV1 and visualize it"""

################################################
    ### Write your code here (read data) ###########
    ################################################

nl1data = np.genfromtxt('csv1.csv',delimiter=',')
for x, y, l in nl1data:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x,y,c=clr)

"""#Train a SVM classifier on the linearly non-separable data by appropriate features crafted from input data
For linearly non-separable data, you need to transform the data in a space where it can be linearly seprable. These features can be exponential, polynomial, trignometric or any other function of actual input features. For example, if your input data is (x1, x2) you can have hand-crafted features as (sin(x1), cos(x1), cos(x2), x1-x2). 
Here you need to think of which hand-crafted features can be best suited for data given to you. Write a function to convert input features to hand-crafted features. Use these features to train a SVM using svm_function.
Note that, if you choose to have L hand-crafted features, SVM will return L+1 dimensional 'w'. 

"""

################################################
### Write your code here for features###########
################################################
def feature(non_lin_data):
  x = non_lin_data[:,:2]
  phi_x = x*x
  return phi_x
phi_x = feature(nl1data)
y = nl1data[:,2]
data = np.hstack((phi_x, y[:,None]))

######################################################
### Write your code here for classification###########
######################################################
datanl1 = np.asarray(data)
X = datanl1[:,:2]
Y = datanl1[:,2]
w1 = svm_function(X, Y, 100000, 0.00025)

x = np.linspace(0,1,100)
plt.plot(x, -(w1[0]*x + w1[2])/w1[1], '-k')
plt.plot(x, -(w1[0]*x + w1[2] + 1)/w1[1], '--g')
plt.plot(x, -(w1[0]*x + w1[2] - 1)/w1[1], '--g')

for x, y, l in datanl1:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
  plt.xlim(0,1)
  plt.ylim(0,1)

"""#Visualize decision boundary
Here, as 'w' retuened by svm_function is (L+1) dimensional, you can not visualize it in the form of line in 2D. To visualize non-linear decision boundary in 2D, you can generate few hundred random data-points and can observe if classifier labels them +1 or -1. Then you can plot this points with different colors to get emperical decision boundary. Write the code for visualization of non-linear decision boundary in next cell.
"""

###################################
    ### Write your code here###########
    ###################################
dataextra = [[np.random.uniform(-1,1), np.random.uniform(-1,1)] for i in range(3000)]
for nl_data in dataextra:
  lin = [None,None]
  lin[0] = nl_data[0]*nl_data[0]
  lin[1] = nl_data[1]*nl_data[1]
  w2 = w1[:2]
  bias = w1[2]
  predict = np.dot(w2,lin) + bias
  if predict >= 0:
    clr = 'red'
  else:
    clr = 'blue'
  plt.scatter(nl_data[0],nl_data[1],c=clr)

"""#Read the Random Non-linear data stored in CSV2"""

###################################
    ### Write your code here###########
    ###################################
nl2data = np.genfromtxt('csv2.csv', delimiter=',')
  
    ###################################################
    ### Write your code here (visualization)###########
    ###################################################
for x, y, l in nl2data:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x,y,c=clr)

"""#Train a SVM classifier on the non linear data by appropriate features and also visualise it"""

###################################
    ### Write your code here###########
    ###################################
phi_x2 = feature(nl2data)
y = nl2data[:,2]
data = np.hstack((phi_x2, y[:,None]))

datanl2 = np.asarray(data)
X = datanl2[:,:2]
Y = datanl2[:,2]
w = svm_function(X, Y, 100000, 0.00025)

x = np.linspace(0,1,100)
plt.plot(x, -(w[0]*x + w[2])/w[1], '-k')
plt.plot(x, -(w[0]*x + w[2] + 1)/w[1], '--g')
plt.plot(x, -(w[0]*x + w[2] - 1)/w[1], '--g')

for x, y, l in datanl2:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
  plt.xlim(0,1)
  plt.ylim(0,1)

"""#Read the Random Non-linear data stored in CSV3"""

###################################
    ### Write your code here###########
    ###################################
nl3data = np.genfromtxt('csv3.csv',delimiter=',')
  
    ###################################################
    ### Write your code here (visualization)###########
    ###################################################
for x, y, l in nl3data:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x,y,c=clr)

"""#Train a SVM classifier on the non linear data by appropriate Feature Engineering and also visualise it"""

###################################
    ### Write your code here###########
    ###################################
phi_x3 = feature(nl3data)
y = nl3data[:,2]
data = np.hstack((phi_x3, y[:,None]))

datanl3 = np.asarray(data)
X = datanl3[:,:2]
Y = datanl3[:,2]
w = svm_function(X, Y, 200000, 0.00002)

x = np.linspace(0,1,100)
plt.plot(x, -(w[0]*x + w[2])/w[1], '-k')
plt.plot(x, -(w[0]*x + w[2] + 1)/w[1], '--g')
plt.plot(x, -(w[0]*x + w[2] - 1)/w[1], '--g')

for x, y, l in datanl3:
  if l == 1: 
    clr = 'red'
  else: 
    clr = 'blue'
  plt.scatter(x, y, c=clr)
  plt.xlim(0,1)
  plt.ylim(0,1)